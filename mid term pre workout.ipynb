{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66132de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from dmba import classificationSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef1d9b",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3afcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')\n",
    "#processed will be used if we have to convert from categorical to numeric which will probably happen\n",
    "processed = pd.get_dummies(df, columns=['SUR_COND']).drop(columns=['SUR_COND_9'])\n",
    "outcome = ''\n",
    "predictors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1278e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed[predictors]\n",
    "y = processed[outcome]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation='relu' for prediction\n",
    "# activation='logistic' for classification\n",
    "clf = MLPClassifier(hidden_layer_sizes=(3), activation='logistic', solver='lbfgs', random_state=1)\n",
    "clf.fit(X, y)\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be2373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training performance\n",
    "classificationSummary(train_y, clf.predict(train_X))\n",
    "\n",
    "# validation performance\n",
    "classificationSummary(valid_y, clf.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c1140",
   "metadata": {},
   "source": [
    "# Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a99960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ae6d1",
   "metadata": {},
   "source": [
    "## Data Approach #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d82712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Products.csv')\n",
    "df.set_index('Transaction', inplace=True)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3bdbd",
   "metadata": {},
   "source": [
    "## Data Approach #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4996b4",
   "metadata": {},
   "source": [
    "So the first one is under the very small circumstacne where we have transaction data that looks like it does in the example \n",
    "This one should work for bascially anything else (which is likely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = df.groupby('what we want grouped in an array')['data'].apply(list).reset_index()\n",
    "transactions = basket['data'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd7900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398ba8a",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## The Actual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9553162",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(df_encoded, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fa342",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "rules = rules[rules['antecedents'].apply(lambda x: len(x) >= 1) & rules['consequents'].apply(lambda x: len(x) >= 1)]\n",
    "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3373f1",
   "metadata": {},
   "source": [
    "# Regression of the simpliest kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.tsa import tsatools, stattools\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics import tsaplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb507e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and convert to time series\n",
    "Amtrak_df = pd.read_csv('')\n",
    "Amtrak_df[''] = pd.to_datetime(Amtrak_df.Month, format='%d/%m/%Y')\n",
    "ridership_ts = pd.Series(Amtrak_df.Ridership.values, index=Amtrak_df.Date, name='Ridership')\n",
    "ridership_ts.index = pd.DatetimeIndex(ridership_ts.index, freq=ridership_ts.index.inferred_freq)\n",
    "ridership_df = tsatools.add_trend(ridership_ts, trend='ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "nValid = 0\n",
    "nTrain = len(ridership_ts) - nValid\n",
    "\n",
    "# partition the data\n",
    "train_df = ridership_df[:nTrain]\n",
    "valid_df = ridership_df[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_lm_poly = sm.ols(formula='y ~ x + I(x**2)', data=train_df).fit()\n",
    "predict_df_expo = ridership_lm_poly.predict(valid_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
